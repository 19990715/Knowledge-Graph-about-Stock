{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84729fc5",
   "metadata": {},
   "source": [
    "# Use bart model to get the subtract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b96b42",
   "metadata": {},
   "source": [
    "training data from CORNEL NEWSROOM:https://lil.nlp.cornell.edu/newsroom/index.html, the format is jsonl.gz    \n",
    "I use it to train the model   \n",
    "data after process is avliable on:https://drive.google.com/file/d/1bn43rT6v-YOyGUEO_VydYWRAWkFU6MLf/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9add39d2",
   "metadata": {},
   "source": [
    "## preprocess the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6810c47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip as gz\n",
    "\n",
    "path = \"train.jsonl.gz\"\n",
    "data = []\n",
    "\n",
    "with gz.open(path) as f:\n",
    "    for ln in f:\n",
    "        obj = json.loads(ln)\n",
    "        data.append(obj)\n",
    "        \n",
    "#data[5:]\n",
    "#data[0]['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e9d79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "text = []\n",
    "summary = []\n",
    "for i in data:\n",
    "    text.append(i['text'])\n",
    "    summary.append(i['summary'])\n",
    "    \n",
    "summary_df = pd.DataFrame()\n",
    "summary_df['text'] = text\n",
    "summary_df['summary'] = summary\n",
    "\n",
    "summary_df[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e05a418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the last 30000 records data\n",
    "sum_df = summary_df[:30000]\n",
    "sum_df.to_csv('sum.csv',index = 'False')\n",
    "textl = []\n",
    "#replace \\n\n",
    "for i in range(0,30000):\n",
    "    ii = \"\".join([s for s in text[i].splitlines(True) if s.strip()])\n",
    "    iii = ii.replace('\\n','')\n",
    "    textl.append(iii)\n",
    "    \n",
    "#print(textl[2])\n",
    "\n",
    "#replace \\r\\n\n",
    "sumar = []\n",
    "for i in sumr:\n",
    "    #ii = \"\".join([s for s in text[i].splitlines(True) if s.strip()])\n",
    "    iii = i.replace('\\r\\n','')\n",
    "    sumar.append(iii)\n",
    "    \n",
    "print(sumar[1])\n",
    "sumr = summary[:30000]\n",
    "summ_df = pd.DataFrame()\n",
    "summ_df['text'] = textl\n",
    "summ_df['summary'] = sumr\n",
    "summ_df.to_csv('sum2.csv',index = 'False')\n",
    "\n",
    "#data for training\n",
    "for i in range(len(textl)):\n",
    "    with open('s2.txt', 'a') as writers: # 打开文件\n",
    "        writers.write(textl[i] + '\\t'+ sumar[i] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce595e4",
   "metadata": {},
   "source": [
    "# use bart model get subtract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7076e19a",
   "metadata": {},
   "source": [
    "package  \n",
    "! pip install datasets  \n",
    "! pip install transformers  \n",
    "! pip install rouge-score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e0064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, data_path, tokenizer):\n",
    "        self.path = data_path\n",
    "        self.max_input_length = 1024\n",
    "        self.max_target_length = 150\n",
    "        # self.tokenizer = AutoTokenizer.from_pretrained(pretrained_model_path)\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def preprocess(self, train_scale=0.8):\n",
    "        with open(self.path,'r') as f:\n",
    "            raw_data = f.readlines()\n",
    "        print(f\"=======data_len: {len(raw_data)}\")\n",
    "        start = int(len(raw_data)*train_scale)\n",
    "        print(f\"======train_len: {start}\")\n",
    "        \n",
    "        raw_train_data = raw_data[:start]\n",
    "        raw_test_data = raw_data[start:]\n",
    "        raw_train_test_data = {'train':{'id':[],'document':[],'summary':[]}, \\\n",
    "                               'test':{'id':[],'document':[],'summary':[]}}        \n",
    "        \n",
    "        for i,item in enumerate(raw_train_data):\n",
    "            if len(item.split('\\t')) != 3:\n",
    "                continue\n",
    "            url,text,label = item.split('\\t')\n",
    "            raw_train_test_data['train']['id'].append(i)\n",
    "            \n",
    "            # document is the train data, summary is the substract label\n",
    "            raw_train_test_data['train']['summary'].append(label.strip())\n",
    "            raw_train_test_data['train']['document'].append(text.strip())\n",
    "\n",
    "        for j,item in enumerate(raw_test_data):\n",
    "            if len(item.split('\\t')) != 3:\n",
    "                continue\n",
    "            url,text,label = item.split('\\t')\n",
    "            raw_train_test_data['test']['id'].append(i+j+1)\n",
    "            raw_train_test_data['test']['summary'].append(label.strip())\n",
    "            raw_train_test_data['test']['document'].append(text.strip())\n",
    "        \n",
    "        def preprocess_function(examples):\n",
    "            \n",
    "            inputs = examples['document']\n",
    "            model_inputs = self.tokenizer(inputs, max_length = self.max_input_length, padding = 'max_length', truncation=True)\n",
    "            \n",
    "            with self.tokenizer.as_target_tokenizer():\n",
    "                labels = self.tokenizer(examples['summary'], max_length = self.max_target_length, padding = 'max_length', truncation = True)\n",
    "            model_inputs['labels'] = labels['input_ids']\n",
    "            return model_inputs\n",
    "        \n",
    "        train_dataset = Dataset.from_dict(raw_train_test_data['train'])\n",
    "        test_dataset = Dataset.from_dict(raw_train_test_data['test'])\n",
    "        tokenized_train_dataset = train_dataset.map(preprocess_function)\n",
    "        tokenized_test_dataset = test_dataset.map(preprocess_function)\n",
    "        return tokenized_train_dataset, tokenized_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ddb196",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import BartForConditionalGeneration\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "#checkpoint = \"distilbart-xsum-9-6\"\n",
    "checkpoint = \"sshleifer/distilbart-xsum-9-6\"\n",
    "model = BartForConditionalGeneration.from_pretrained(checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b964caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluating metric use the rouge_score\n",
    "import numpy as np\n",
    "from rouge_score import rouge_scorer, scoring\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "  \n",
    "\n",
    "\n",
    "def compute(predictions, references, rouge_types=None, use_agregator=True, use_stemmer=False):\n",
    "    if rouge_types is None:\n",
    "        rouge_types = [\"rouge1\", \"rougeL\"]\n",
    "\n",
    "    scorer = rouge_scorer.RougeScorer(rouge_types=rouge_types, use_stemmer=True)\n",
    "    if use_agregator:\n",
    "        aggregator = scoring.BootstrapAggregator()\n",
    "    else:\n",
    "        scores = []\n",
    "\n",
    "    for ref, pred in zip(references, predictions):\n",
    "        score = scorer.score(ref, pred)\n",
    "        if use_agregator:\n",
    "            aggregator.add_scores(score)\n",
    "        else:\n",
    "            scores.append(score)\n",
    "\n",
    "    if use_agregator:\n",
    "        result = aggregator.aggregate()\n",
    "    else:\n",
    "        result = {}\n",
    "        for key in scores[0]:\n",
    "            result[key] = list(score[key] for score in scores)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "#metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    result = compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    # Extract a few results\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length\n",
    "    #prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    #result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d684f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure Hyperparameters\n",
    "batch_size = 1\n",
    "args = Seq2SeqTrainingArguments( \\\n",
    "    \"/Users/fusi/Desktop/ds/individual_project/demo/model\", \\\n",
    "    evaluation_strategy = 'steps', \\\n",
    "    learning_rate = 5e-5, \\\n",
    "    per_device_train_batch_size = batch_size, \\\n",
    "    per_device_eval_batch_size = batch_size, \\\n",
    "    weight_decay = 0.01, \\\n",
    "    save_steps = 200, \\\n",
    "    #save_total_limit = 5, \\\n",
    "    num_train_epochs = 250, \\\n",
    "    predict_with_generate = True, \\\n",
    "    eval_steps = 200, \\\n",
    "    logging_first_step=True, \\\n",
    "    report_to=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4143e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use transformers api to train the data\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model = model, padding=True)\n",
    "data = Data('s2.txt', tokenizer)\n",
    "tokenized_train_dataset, tokenized_test_dataset = data.preprocess()\n",
    "trainer =Seq2SeqTrainer( \\\n",
    "                       model, \\\n",
    "                       args, \\\n",
    "                       train_dataset = tokenized_train_dataset, \\\n",
    "                       eval_dataset = tokenized_test_dataset, \\\n",
    "                       data_collator = data_collator, \\\n",
    "                       tokenizer = tokenizer, \\\n",
    "                       compute_metrics = compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2234f5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f2f017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    inputs = tokenizer([sentence],max_length = 1024, return_tensors='pt')\n",
    "    summary_ids = model.generate(inputs['input_ids'], num_beams=70, max_length=500,min_length=50,early_stopping=True)\n",
    "    summary = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n",
    "    return ' '.join(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f963b475",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "pre = [] \n",
    "with open('summary.txt','r') as f :\n",
    "  for line in f.readlines():\n",
    "    line = line.strip('\\n')\n",
    "    l.append(line)\n",
    "print(len(l))\n",
    "for i in l:\n",
    "  p = predict(i)\n",
    "  pre.append(p)\n",
    "    \n",
    "df.to_csv('sum.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
